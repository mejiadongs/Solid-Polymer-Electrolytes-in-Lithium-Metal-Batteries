{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in checkpoint: dict_keys(['epoch', 'state_dict', 'best_mae_error', 'optimizer', 'normalizer', 'args'])\n",
      "Model arguments found in checkpoint:\n",
      "{'data_options': ['data/sample-regression/dielectricity'], 'task': 'regression', 'disable_cuda': False, 'workers': 0, 'epochs': 100, 'start_epoch': 0, 'batch_size': 256, 'lr': 0.01, 'lr_milestones': [100], 'momentum': 0.9, 'weight_decay': 0, 'print_freq': 10, 'resume': '', 'radius': 20.0, 'train_ratio': 0.6, 'train_size': None, 'val_ratio': 0.2, 'val_size': None, 'test_ratio': 0.2, 'test_size': None, 'optim': 'SGD', 'atom_fea_len': 64, 'h_fea_len': 128, 'n_conv': 3, 'n_h': 1, 'cuda': True}\n",
      "Calculated nbr_fea_len: 165\n",
      "atom_fea_len: 64\n",
      "orig_atom_fea_len not found in args, using value from embedding layer\n",
      "Model arguments to be used:\n",
      "{'atom_fea_len': 64, 'nbr_fea_len': 165, 'n_conv': 3, 'h_fea_len': 128, 'n_h': 1, 'classification': False, 'orig_atom_fea_len': 92}\n",
      "Model loaded successfully with filtered weights!\n",
      "Model structure:\n",
      "CrystalGraphConvNetWithHooks(\n",
      "  (embedding): Linear(in_features=92, out_features=64, bias=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-2): 3 x ModifiedConvLayer(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1, threshold=20)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1, threshold=20)\n",
      "    )\n",
      "  )\n",
      "  (conv_to_fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1, threshold=20)\n",
      "  (fc_out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Input data shapes:\n",
      "atom_fea shape: torch.Size([32, 92])\n",
      "nbr_fea shape: torch.Size([32, 12, 41])\n",
      "nbr_fea_idx shape: torch.Size([32, 12])\n",
      "crystal_atom_idx type: <class 'list'>\n",
      "crystal_atom_idx: [tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])]\n",
      "target shape: torch.Size([1, 1])\n",
      "chemical_formula: C9Cl4F8H7NO3\n",
      "Processed crystal_atom_idx shape: torch.Size([32])\n",
      "CrystalGraphConvNetWithHooks - Input shapes:\n",
      "  atom_fea: torch.Size([32, 92])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n",
      "  crystal_atom_idx: torch.Size([32])\n",
      "  After embedding, atom_fea shape: torch.Size([32, 64])\n",
      "  Before conv 1, atom_fea shape: torch.Size([32, 64])\n",
      "ModifiedConvLayer - Input shapes:\n",
      "  atom_in_fea: torch.Size([32, 64])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n",
      "  total_nbr_fea shape: torch.Size([32, 12, 169])\n",
      "  fc_full input shape: torch.Size([384, 169])\n",
      "  fc_full weight shape: torch.Size([128, 169])\n",
      "  After conv 1, atom_fea shape: torch.Size([32, 64])\n",
      "  Before conv 2, atom_fea shape: torch.Size([32, 64])\n",
      "ModifiedConvLayer - Input shapes:\n",
      "  atom_in_fea: torch.Size([32, 64])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n",
      "  total_nbr_fea shape: torch.Size([32, 12, 169])\n",
      "  fc_full input shape: torch.Size([384, 169])\n",
      "  fc_full weight shape: torch.Size([128, 169])\n",
      "  After conv 2, atom_fea shape: torch.Size([32, 64])\n",
      "  Before conv 3, atom_fea shape: torch.Size([32, 64])\n",
      "ModifiedConvLayer - Input shapes:\n",
      "  atom_in_fea: torch.Size([32, 64])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n",
      "  total_nbr_fea shape: torch.Size([32, 12, 169])\n",
      "  fc_full input shape: torch.Size([384, 169])\n",
      "  fc_full weight shape: torch.Size([128, 169])\n",
      "  After conv 3, atom_fea shape: torch.Size([32, 64])\n",
      "Warning: Unexpected type for crystal_atom_idx: <class 'torch.Tensor'>. Converting to a list.\n",
      "  Processed crystal_atom_idx: [torch.Size([32])]\n",
      "  After pooling, crys_fea shape: torch.Size([1, 64])\n",
      "  After conv_to_fc, crys_fea shape: torch.Size([1, 128])\n",
      "  After conv_to_fc_softplus, crys_fea shape: torch.Size([1, 128])\n",
      "  Final output shape: torch.Size([1, 1])\n",
      "Model output shape: torch.Size([1, 1])\n",
      "Model output value: 0.2687295973300934\n",
      "Intermediate outputs:\n",
      "embedding: torch.Size([32, 64])\n",
      "conv_to_fc: torch.Size([1, 128])\n",
      "fc_out: torch.Size([1, 1])\n",
      "Cannot analyze feature activation for scalar output in layer fc_out\n",
      "Model dissection completed. Check the output images for visualization results.\n",
      "\n",
      "Additional Analysis:\n",
      "1. Number of parameters in each layer:\n",
      "embedding.weight: 5888\n",
      "embedding.bias: 64\n",
      "convs.0.bn2.weight: 64\n",
      "convs.0.bn2.bias: 64\n",
      "convs.0.fc_full.weight: 21632\n",
      "convs.0.fc_full.bias: 128\n",
      "convs.0.bn1.weight: 128\n",
      "convs.0.bn1.bias: 128\n",
      "convs.1.bn2.weight: 64\n",
      "convs.1.bn2.bias: 64\n",
      "convs.1.fc_full.weight: 21632\n",
      "convs.1.fc_full.bias: 128\n",
      "convs.1.bn1.weight: 128\n",
      "convs.1.bn1.bias: 128\n",
      "convs.2.bn2.weight: 64\n",
      "convs.2.bn2.bias: 64\n",
      "convs.2.fc_full.weight: 21632\n",
      "convs.2.fc_full.bias: 128\n",
      "convs.2.bn1.weight: 128\n",
      "convs.2.bn1.bias: 128\n",
      "conv_to_fc.weight: 8192\n",
      "conv_to_fc.bias: 128\n",
      "fc_out.weight: 128\n",
      "fc_out.bias: 1\n",
      "\n",
      "2. Layer output statistics:\n",
      "embedding:\n",
      "  Mean: -0.0090\n",
      "  Std: 0.1810\n",
      "  Min: -0.6353\n",
      "  Max: 0.6215\n",
      "conv_to_fc:\n",
      "  Mean: -0.9067\n",
      "  Std: 0.4664\n",
      "  Min: -2.5845\n",
      "  Max: 0.1318\n",
      "fc_out:\n",
      "  Mean: 0.2687\n",
      "  Std: 0.0000\n",
      "  Min: 0.2687\n",
      "  Max: 0.2687\n",
      "\n",
      "Model dissection and analysis completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 假设这些导入是可用的，如果不是，您可能需要调整导入语句\n",
    "from cgcnn.model import CrystalGraphConvNet\n",
    "from cgcnn.data import CIFData, collate_pool\n",
    "\n",
    "class ModifiedConvLayer(torch.nn.Module):\n",
    "    def __init__(self, atom_fea_len, nbr_fea_len):\n",
    "        super(ModifiedConvLayer, self).__init__()\n",
    "        self.atom_fea_len = atom_fea_len\n",
    "        self.nbr_fea_len = nbr_fea_len\n",
    "        self.fc_full = None  # We'll initialize this in the forward pass\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.softplus1 = torch.nn.Softplus()\n",
    "        self.bn1 = None  # We'll initialize this in the forward pass\n",
    "        self.bn2 = torch.nn.BatchNorm1d(self.atom_fea_len)\n",
    "        self.softplus2 = torch.nn.Softplus()\n",
    "\n",
    "    def forward(self, atom_in_fea, nbr_fea, nbr_fea_idx):\n",
    "        N, M = nbr_fea_idx.shape\n",
    "        print(f\"ModifiedConvLayer - Input shapes:\")\n",
    "        print(f\"  atom_in_fea: {atom_in_fea.shape}\")\n",
    "        print(f\"  nbr_fea: {nbr_fea.shape}\")\n",
    "        print(f\"  nbr_fea_idx: {nbr_fea_idx.shape}\")\n",
    "\n",
    "        atom_nbr_fea = atom_in_fea[nbr_fea_idx, :]\n",
    "        total_nbr_fea = torch.cat(\n",
    "            [atom_in_fea.unsqueeze(1).expand(N, M, self.atom_fea_len),\n",
    "             atom_nbr_fea, nbr_fea], dim=2)\n",
    "        \n",
    "        print(f\"  total_nbr_fea shape: {total_nbr_fea.shape}\")\n",
    "        \n",
    "        # Dynamically create fc_full and bn1 layers based on actual input size\n",
    "        if self.fc_full is None:\n",
    "            in_features = total_nbr_fea.shape[-1]\n",
    "            out_features = 2 * self.atom_fea_len\n",
    "            self.fc_full = torch.nn.Linear(in_features, out_features)\n",
    "            self.bn1 = torch.nn.BatchNorm1d(out_features)\n",
    "        \n",
    "        print(f\"  fc_full input shape: {total_nbr_fea.view(-1, total_nbr_fea.shape[-1]).shape}\")\n",
    "        print(f\"  fc_full weight shape: {self.fc_full.weight.shape}\")\n",
    "\n",
    "        total_gated_fea = self.fc_full(total_nbr_fea.view(-1, total_nbr_fea.shape[-1]))\n",
    "        total_gated_fea = self.bn1(total_gated_fea).view(N, M, 2*self.atom_fea_len)\n",
    "        nbr_filter, nbr_core = total_gated_fea.chunk(2, dim=2)\n",
    "        nbr_filter = self.sigmoid(nbr_filter)\n",
    "        nbr_core = self.softplus1(nbr_core)\n",
    "        nbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)\n",
    "        nbr_sumed = self.bn2(nbr_sumed)\n",
    "        out = self.softplus2(atom_in_fea + nbr_sumed)\n",
    "        return out\n",
    "\n",
    "class CrystalGraphConvNetWithHooks(CrystalGraphConvNet):\n",
    "    def __init__(self, orig_atom_fea_len, nbr_fea_len,\n",
    "                 atom_fea_len=64, n_conv=3, h_fea_len=128, n_h=1,\n",
    "                 classification=False):\n",
    "        super().__init__(orig_atom_fea_len, nbr_fea_len,\n",
    "                         atom_fea_len=atom_fea_len, n_conv=n_conv,\n",
    "                         h_fea_len=h_fea_len, n_h=n_h,\n",
    "                         classification=classification)\n",
    "        self.intermediate_outputs = {}\n",
    "        self.atom_fea_len = atom_fea_len\n",
    "        self.nbr_fea_len = nbr_fea_len\n",
    "        \n",
    "        # Replace the original convs with our modified version\n",
    "        self.convs = torch.nn.ModuleList([ModifiedConvLayer(\n",
    "            atom_fea_len=self.atom_fea_len,\n",
    "            nbr_fea_len=self.nbr_fea_len)\n",
    "            for _ in range(n_conv)])\n",
    "\n",
    "    def add_hook(self, name):\n",
    "        def hook(module, input, output):\n",
    "            self.intermediate_outputs[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    def forward(self, atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx):\n",
    "        print(f\"CrystalGraphConvNetWithHooks - Input shapes:\")\n",
    "        print(f\"  atom_fea: {atom_fea.shape}\")\n",
    "        print(f\"  nbr_fea: {nbr_fea.shape}\")\n",
    "        print(f\"  nbr_fea_idx: {nbr_fea_idx.shape}\")\n",
    "        print(f\"  crystal_atom_idx: {crystal_atom_idx.shape if isinstance(crystal_atom_idx, torch.Tensor) else type(crystal_atom_idx)}\")\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv1d) or isinstance(module, torch.nn.Linear):\n",
    "                module.register_forward_hook(self.add_hook(name))\n",
    "        \n",
    "        atom_fea = self.embedding(atom_fea)\n",
    "        print(f\"  After embedding, atom_fea shape: {atom_fea.shape}\")\n",
    "        \n",
    "        for i, conv_func in enumerate(self.convs):\n",
    "            print(f\"  Before conv {i+1}, atom_fea shape: {atom_fea.shape}\")\n",
    "            atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
    "            print(f\"  After conv {i+1}, atom_fea shape: {atom_fea.shape}\")\n",
    "        \n",
    "        # Handle crystal_atom_idx\n",
    "        if isinstance(crystal_atom_idx, torch.Tensor) and crystal_atom_idx.dim() == 0:\n",
    "            print(\"Warning: crystal_atom_idx is a 0-d tensor. Converting to a list.\")\n",
    "            crystal_atom_idx = [torch.arange(atom_fea.shape[0], dtype=torch.long)]\n",
    "        elif not isinstance(crystal_atom_idx, list):\n",
    "            print(f\"Warning: Unexpected type for crystal_atom_idx: {type(crystal_atom_idx)}. Converting to a list.\")\n",
    "            crystal_atom_idx = [torch.arange(atom_fea.shape[0], dtype=torch.long)]\n",
    "\n",
    "        print(f\"  Processed crystal_atom_idx: {[idx.shape if isinstance(idx, torch.Tensor) else len(idx) for idx in crystal_atom_idx]}\")\n",
    "        \n",
    "        crys_fea = self.pooling(atom_fea, crystal_atom_idx)\n",
    "        print(f\"  After pooling, crys_fea shape: {crys_fea.shape}\")\n",
    "        \n",
    "        crys_fea = self.conv_to_fc(self.conv_to_fc_softplus(crys_fea))\n",
    "        print(f\"  After conv_to_fc, crys_fea shape: {crys_fea.shape}\")\n",
    "        \n",
    "        crys_fea = self.conv_to_fc_softplus(crys_fea)\n",
    "        print(f\"  After conv_to_fc_softplus, crys_fea shape: {crys_fea.shape}\")\n",
    "        \n",
    "        out = self.fc_out(crys_fea)\n",
    "        print(f\"  Final output shape: {out.shape}\")\n",
    "\n",
    "        return out\n",
    "\n",
    "# 加载模型\n",
    "checkpoint = torch.load('model_best.pth.tar', map_location=torch.device('cpu'))\n",
    "\n",
    "print(\"Keys in checkpoint:\", checkpoint.keys())\n",
    "\n",
    "# 提取模型参数\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "# 从checkpoint的args中提取模型参数\n",
    "if 'args' in checkpoint:\n",
    "    args = checkpoint['args']\n",
    "    print(\"Model arguments found in checkpoint:\")\n",
    "    print(args)\n",
    "    \n",
    "    # 从第一个卷积层的权重形状精确计算参数\n",
    "    conv_weight_shape = state_dict['convs.0.fc_full.weight'].shape\n",
    "    total_fea_len = conv_weight_shape[1]\n",
    "    atom_fea_len = args.get('atom_fea_len', 64)\n",
    "    nbr_fea_len = total_fea_len - atom_fea_len\n",
    "    \n",
    "    print(f\"Calculated nbr_fea_len: {nbr_fea_len}\")\n",
    "    print(f\"atom_fea_len: {atom_fea_len}\")\n",
    "    \n",
    "    model_args = {\n",
    "        'atom_fea_len': atom_fea_len,\n",
    "        'nbr_fea_len': nbr_fea_len,\n",
    "        'n_conv': args.get('n_conv', 3),\n",
    "        'h_fea_len': args.get('h_fea_len', 128),\n",
    "        'n_h': args.get('n_h', 1),\n",
    "        'classification': False  # 假设这是回归任务\n",
    "    }\n",
    "    \n",
    "    # 检查 orig_atom_fea_len\n",
    "    if 'orig_atom_fea_len' in args:\n",
    "        model_args['orig_atom_fea_len'] = args['orig_atom_fea_len']\n",
    "    else:\n",
    "        print(\"orig_atom_fea_len not found in args, using value from embedding layer\")\n",
    "        model_args['orig_atom_fea_len'] = state_dict['embedding.weight'].shape[1]\n",
    "else:\n",
    "    raise ValueError(\"No 'args' found in checkpoint. Cannot determine model parameters.\")\n",
    "\n",
    "print(\"Model arguments to be used:\")\n",
    "print(model_args)\n",
    "\n",
    "# 创建模型实例\n",
    "model = CrystalGraphConvNetWithHooks(**model_args)\n",
    "\n",
    "# 手动过滤掉不匹配的层\n",
    "model_state_dict = model.state_dict()\n",
    "filtered_state_dict = {k: v for k, v in state_dict.items() if k in model_state_dict and v.size() == model_state_dict[k].size()}\n",
    "\n",
    "# 加载过滤后的权重\n",
    "try:\n",
    "    model.load_state_dict(filtered_state_dict, strict=False)\n",
    "    print(\"Model loaded successfully with filtered weights!\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error loading state dict: {e}\")\n",
    "    print(\"Model structure:\")\n",
    "    print(model)\n",
    "    print(\"\\nState dict keys:\")\n",
    "    print(state_dict.keys())\n",
    "    raise\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 打印模型结构\n",
    "print(\"Model structure:\")\n",
    "print(model)\n",
    "\n",
    "# 加载数据集\n",
    "dataset = CIFData('data/sample-regression/dielectricity')\n",
    "loader = DataLoader(dataset, batch_size=1, collate_fn=collate_pool)\n",
    "\n",
    "# 获取一个样本的数据\n",
    "sample_input = next(iter(loader))\n",
    "\n",
    "# 解包样本数据\n",
    "atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx = sample_input[0]\n",
    "target = sample_input[1]\n",
    "chemical_formula = sample_input[2][0]\n",
    "\n",
    "print(f\"Input data shapes:\")\n",
    "print(f\"atom_fea shape: {atom_fea.shape}\")\n",
    "print(f\"nbr_fea shape: {nbr_fea.shape}\")\n",
    "print(f\"nbr_fea_idx shape: {nbr_fea_idx.shape}\")\n",
    "print(f\"crystal_atom_idx type: {type(crystal_atom_idx)}\")\n",
    "print(f\"crystal_atom_idx: {crystal_atom_idx}\")\n",
    "print(f\"target shape: {target.shape}\")\n",
    "print(f\"chemical_formula: {chemical_formula}\")\n",
    "\n",
    "# 确保所有输入都是正确的张量类型\n",
    "atom_fea = atom_fea.float()\n",
    "nbr_fea = nbr_fea.float()\n",
    "nbr_fea_idx = nbr_fea_idx.long()\n",
    "\n",
    "# 处理 crystal_atom_idx\n",
    "if isinstance(crystal_atom_idx, list) and len(crystal_atom_idx) == 1 and isinstance(crystal_atom_idx[0], torch.Tensor):\n",
    "    crystal_atom_idx = crystal_atom_idx[0].long()\n",
    "elif not isinstance(crystal_atom_idx, torch.Tensor):\n",
    "    print(f\"Warning: Unexpected type for crystal_atom_idx: {type(crystal_atom_idx)}. Converting to tensor.\")\n",
    "    crystal_atom_idx = torch.arange(atom_fea.shape[0], dtype=torch.long)\n",
    "\n",
    "print(f\"Processed crystal_atom_idx shape: {crystal_atom_idx.shape}\")\n",
    "\n",
    "\n",
    "def visualize_layer_output(layer_name, output):\n",
    "    output = output.squeeze().cpu().numpy()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if output.ndim == 0:  # Scalar output\n",
    "        plt.text(0.5, 0.5, f\"Scalar Output: {output.item():.4f}\", \n",
    "                 horizontalalignment='center', verticalalignment='center', fontsize=20)\n",
    "        plt.axis('off')\n",
    "    elif output.ndim == 1:\n",
    "        plt.plot(output)\n",
    "        plt.title(f'Output of {layer_name}')\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Value')\n",
    "    elif output.ndim == 2:\n",
    "        plt.imshow(output, aspect='auto', cmap='viridis')\n",
    "        plt.title(f'Output of {layer_name}')\n",
    "        plt.colorbar()\n",
    "        plt.xlabel('Feature dimension')\n",
    "        plt.ylabel('Sample index')\n",
    "    else:\n",
    "        print(f\"Cannot visualize output of shape {output.shape} for layer {layer_name}\")\n",
    "        return\n",
    "    \n",
    "    plt.savefig(f'{layer_name}_output.png')\n",
    "    plt.close()\n",
    "\n",
    "def analyze_feature_activation(layer_name, output):\n",
    "    output = output.squeeze().cpu().numpy()\n",
    "    if output.ndim == 0:  # Scalar output\n",
    "        print(f\"Cannot analyze feature activation for scalar output in layer {layer_name}\")\n",
    "        return\n",
    "    elif output.ndim == 1:\n",
    "        mean_activation = output\n",
    "    else:\n",
    "        mean_activation = np.mean(output, axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(mean_activation)), mean_activation)\n",
    "    plt.title(f'Mean Feature Activation in {layer_name}')\n",
    "    plt.xlabel('Feature index')\n",
    "    plt.ylabel('Mean activation')\n",
    "    plt.savefig(f'{layer_name}_mean_activation.png')\n",
    "    plt.close()\n",
    "\n",
    "# 运行模型\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        output = model(atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx)\n",
    "    print(\"Model output shape:\", output.shape)\n",
    "    print(\"Model output value:\", output.item())\n",
    "except Exception as e:\n",
    "    print(f\"Error during model execution: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# 打印中间层输出\n",
    "print(\"Intermediate outputs:\")\n",
    "for name, output in model.intermediate_outputs.items():\n",
    "    print(f\"{name}: {output.shape}\")\n",
    "\n",
    "# 执行可视化\n",
    "for name, output in model.intermediate_outputs.items():\n",
    "    try:\n",
    "        visualize_layer_output(name, output)\n",
    "        analyze_feature_activation(name, output)\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing {name}: {str(e)}\")\n",
    "\n",
    "print(\"Model dissection completed. Check the output images for visualization results.\")\n",
    "\n",
    "# 额外的分析\n",
    "print(\"\\nAdditional Analysis:\")\n",
    "print(\"1. Number of parameters in each layer:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "print(\"\\n2. Layer output statistics:\")\n",
    "for name, output in model.intermediate_outputs.items():\n",
    "    output_np = output.cpu().numpy()\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Mean: {np.mean(output_np):.4f}\")\n",
    "    print(f\"  Std: {np.std(output_np):.4f}\")\n",
    "    print(f\"  Min: {np.min(output_np):.4f}\")\n",
    "    print(f\"  Max: {np.max(output_np):.4f}\")\n",
    "\n",
    "print(\"\\nModel dissection and analysis completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight:\n",
      "  Shape: torch.Size([64, 92])\n",
      "  Mean: 0.0008\n",
      "  Std: 0.0605\n",
      "  Min: -0.1301\n",
      "  Max: 0.1380\n",
      "embedding.bias:\n",
      "  Shape: torch.Size([64])\n",
      "  Mean: -0.0088\n",
      "  Std: 0.0610\n",
      "  Min: -0.1051\n",
      "  Max: 0.1058\n",
      "convs.0.bn2.weight:\n",
      "  Shape: torch.Size([64])\n",
      "  Mean: 1.0001\n",
      "  Std: 0.0082\n",
      "  Min: 0.9857\n",
      "  Max: 1.0309\n",
      "convs.0.bn2.bias:\n",
      "  Shape: torch.Size([64])\n",
      "  Mean: -0.0014\n",
      "  Std: 0.0035\n",
      "  Min: -0.0091\n",
      "  Max: 0.0112\n",
      "convs.0.fc_full.weight:\n",
      "  Shape: torch.Size([128, 169])\n",
      "  Mean: 0.0000\n",
      "  Std: 0.0444\n",
      "  Min: -0.0769\n",
      "  Max: 0.0769\n",
      "convs.0.fc_full.bias:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: -0.0038\n",
      "  Std: 0.0468\n",
      "  Min: -0.0764\n",
      "  Max: 0.0768\n",
      "convs.0.bn1.weight:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: 1.0000\n",
      "  Std: 0.0000\n",
      "  Min: 1.0000\n",
      "  Max: 1.0000\n",
      "convs.0.bn1.bias:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: 0.0000\n",
      "  Std: 0.0000\n",
      "  Min: 0.0000\n",
      "  Max: 0.0000\n",
      "convs.1.bn2.weight:\n",
      "  Shape: torch.Size([64])\n",
      "  Mean: 1.0022\n",
      "  Std: 0.0067\n",
      "  Min: 0.9866\n",
      "  Max: 1.0220\n",
      "convs.1.bn2.bias:\n",
      "  Shape: torch.Size([64])\n",
      "  Mean: -0.0012\n",
      "  Std: 0.0036\n",
      "  Min: -0.0106\n",
      "  Max: 0.0110\n",
      "convs.1.fc_full.weight:\n",
      "  Shape: torch.Size([128, 169])\n",
      "  Mean: 0.0002\n",
      "  Std: 0.0443\n",
      "  Min: -0.0769\n",
      "  Max: 0.0769\n",
      "convs.1.fc_full.bias:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: 0.0022\n",
      "  Std: 0.0441\n",
      "  Min: -0.0761\n",
      "  Max: 0.0764\n",
      "convs.1.bn1.weight:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: 1.0000\n",
      "  Std: 0.0000\n",
      "  Min: 1.0000\n",
      "  Max: 1.0000\n",
      "convs.1.bn1.bias:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: 0.0000\n",
      "  Std: 0.0000\n",
      "  Min: 0.0000\n",
      "  Max: 0.0000\n",
      "convs.2.bn2.weight:\n",
      "  Shape: torch.Size([64])\n",
      "  Mean: 1.0063\n",
      "  Std: 0.0102\n",
      "  Min: 0.9906\n",
      "  Max: 1.0452\n",
      "convs.2.bn2.bias:\n",
      "  Shape: torch.Size([64])\n",
      "  Mean: -0.0014\n",
      "  Std: 0.0039\n",
      "  Min: -0.0091\n",
      "  Max: 0.0119\n",
      "convs.2.fc_full.weight:\n",
      "  Shape: torch.Size([128, 169])\n",
      "  Mean: 0.0003\n",
      "  Std: 0.0444\n",
      "  Min: -0.0769\n",
      "  Max: 0.0769\n",
      "convs.2.fc_full.bias:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: -0.0021\n",
      "  Std: 0.0431\n",
      "  Min: -0.0769\n",
      "  Max: 0.0766\n",
      "convs.2.bn1.weight:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: 1.0000\n",
      "  Std: 0.0000\n",
      "  Min: 1.0000\n",
      "  Max: 1.0000\n",
      "convs.2.bn1.bias:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: 0.0000\n",
      "  Std: 0.0000\n",
      "  Min: 0.0000\n",
      "  Max: 0.0000\n",
      "conv_to_fc.weight:\n",
      "  Shape: torch.Size([128, 64])\n",
      "  Mean: -0.0078\n",
      "  Std: 0.0728\n",
      "  Min: -0.2003\n",
      "  Max: 0.1616\n",
      "conv_to_fc.bias:\n",
      "  Shape: torch.Size([128])\n",
      "  Mean: -0.0015\n",
      "  Std: 0.0718\n",
      "  Min: -0.1346\n",
      "  Max: 0.1193\n",
      "fc_out.weight:\n",
      "  Shape: torch.Size([1, 128])\n",
      "  Mean: -0.0025\n",
      "  Std: 0.0783\n",
      "  Min: -0.1619\n",
      "  Max: 0.3166\n",
      "fc_out.bias:\n",
      "  Shape: torch.Size([1])\n",
      "  Mean: -0.1120\n",
      "  Std: nan\n",
      "  Min: -0.1120\n",
      "  Max: -0.1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_50800\\1144139257.py:6: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ..\\aten\\src\\ATen\\native\\ReduceOps.cpp:1760.)\n",
      "  print(f\"  Std: {param.data.std().item():.4f}\")\n"
     ]
    }
   ],
   "source": [
    "#每层的权重和偏置统计：\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Shape: {param.shape}\")\n",
    "        print(f\"  Mean: {param.data.mean().item():.4f}\")\n",
    "        print(f\"  Std: {param.data.std().item():.4f}\")\n",
    "        print(f\"  Min: {param.data.min().item():.4f}\")\n",
    "        print(f\"  Max: {param.data.max().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每个卷积层的输出统计：\n",
    "def conv_hook(module, input, output):\n",
    "    print(f\"Conv layer output stats:\")\n",
    "    print(f\"  Shape: {output.shape}\")\n",
    "    print(f\"  Mean: {output.mean().item():.4f}\")\n",
    "    print(f\"  Std: {output.std().item():.4f}\")\n",
    "    print(f\"  Min: {output.min().item():.4f}\")\n",
    "    print(f\"  Max: {output.max().item():.4f}\")\n",
    "\n",
    "for conv in model.convs:\n",
    "    conv.register_forward_hook(conv_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrystalGraphConvNetWithHooks - Input shapes:\n",
      "  atom_fea: torch.Size([32, 92])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n",
      "  crystal_atom_idx: torch.Size([32])\n",
      "  After embedding, atom_fea shape: torch.Size([32, 64])\n",
      "  Before conv 1, atom_fea shape: torch.Size([32, 64])\n",
      "ModifiedConvLayer - Input shapes:\n",
      "  atom_in_fea: torch.Size([32, 64])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Linear: 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\conda\\envs\\cgcnn\\Lib\\site-packages\\torchinfo\\torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32md:\\conda\\envs\\cgcnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\cgcnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[3], line 95\u001b[0m, in \u001b[0;36mCrystalGraphConvNetWithHooks.forward\u001b[1;34m(self, atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Before conv \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, atom_fea shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00matom_fea\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m atom_fea \u001b[38;5;241m=\u001b[39m \u001b[43mconv_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43matom_fea\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbr_fea\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbr_fea_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  After conv \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, atom_fea shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00matom_fea\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\conda\\envs\\cgcnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\cgcnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m, in \u001b[0;36mModifiedConvLayer.forward\u001b[1;34m(self, atom_in_fea, nbr_fea, nbr_fea_idx)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  nbr_fea_idx: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnbr_fea_idx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m atom_nbr_fea \u001b[38;5;241m=\u001b[39m \u001b[43matom_in_fea\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnbr_fea_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     30\u001b[0m total_nbr_fea \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m     31\u001b[0m     [atom_in_fea\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(N, M, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matom_fea_len),\n\u001b[0;32m     32\u001b[0m      atom_nbr_fea, nbr_fea], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: tensors used as indices must be long, int, byte or bool tensors",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchinfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m----> 3\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m92\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m41\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\cgcnn\\Lib\\site-packages\\torchinfo\\torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m validate_user_params(\n\u001b[0;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[0;32m    218\u001b[0m )\n\u001b[0;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[0;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[0;32m    222\u001b[0m )\n\u001b[1;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[0;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[0;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[0;32m    229\u001b[0m )\n",
      "File \u001b[1;32md:\\conda\\envs\\cgcnn\\Lib\\site-packages\\torchinfo\\torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Linear: 1]"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=[(32, 92), (32, 12, 41), (32, 12), (32,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_weight_distribution(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(param.data.cpu().numpy().flatten(), kde=True)\n",
    "            plt.title(f'Weight Distribution of {name}')\n",
    "            plt.xlabel('Weight Value')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.savefig(f'weight_dist_{name.replace(\".\", \"_\")}.png')\n",
    "            plt.close()\n",
    "\n",
    "plot_weight_distribution(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix shape: (34, 34)\n",
      "Number of features plotted: 34\n"
     ]
    }
   ],
   "source": [
    "#特征相关性热图\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_feature_correlation(features):\n",
    "    # 移除常量特征和包含 NaN 的特征\n",
    "    features = features.T  # 转置以便每列是一个特征\n",
    "    non_constant = np.any(features != features[0, :], axis=1)\n",
    "    non_nan = ~np.isnan(features).any(axis=1)\n",
    "    valid_features = non_constant & non_nan\n",
    "    features = features[valid_features]\n",
    "    \n",
    "    if features.shape[0] == 0:\n",
    "        print(\"No valid features to compute correlation.\")\n",
    "        return\n",
    "    \n",
    "    # 计算相关性，忽略 NaN 值\n",
    "    corr = np.ma.corrcoef(features)\n",
    "    if isinstance(corr, np.ma.MaskedArray):\n",
    "        corr = corr.filled(np.nan)  # 将掩码值替换为 NaN\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr, cmap='coolwarm', center=0, mask=np.isnan(corr))\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.savefig('feature_correlation.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Correlation matrix shape: {corr.shape}\")\n",
    "    print(f\"Number of features plotted: {features.shape[0]}\")\n",
    "\n",
    "# 使用修改后的函数\n",
    "plot_feature_correlation(atom_fea.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrystalGraphConvNetWithHooks - Input shapes:\n",
      "  atom_fea: torch.Size([32, 92])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n",
      "  crystal_atom_idx: torch.Size([32])\n",
      "  After embedding, atom_fea shape: torch.Size([32, 64])\n",
      "  Before conv 1, atom_fea shape: torch.Size([32, 64])\n",
      "ModifiedConvLayer - Input shapes:\n",
      "  atom_in_fea: torch.Size([32, 64])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n",
      "  total_nbr_fea shape: torch.Size([32, 12, 169])\n",
      "  fc_full input shape: torch.Size([384, 169])\n",
      "  fc_full weight shape: torch.Size([128, 169])\n",
      "  After conv 1, atom_fea shape: torch.Size([32, 64])\n",
      "  Before conv 2, atom_fea shape: torch.Size([32, 64])\n",
      "ModifiedConvLayer - Input shapes:\n",
      "  atom_in_fea: torch.Size([32, 64])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n",
      "  total_nbr_fea shape: torch.Size([32, 12, 169])\n",
      "  fc_full input shape: torch.Size([384, 169])\n",
      "  fc_full weight shape: torch.Size([128, 169])\n",
      "  After conv 2, atom_fea shape: torch.Size([32, 64])\n",
      "  Before conv 3, atom_fea shape: torch.Size([32, 64])\n",
      "ModifiedConvLayer - Input shapes:\n",
      "  atom_in_fea: torch.Size([32, 64])\n",
      "  nbr_fea: torch.Size([32, 12, 41])\n",
      "  nbr_fea_idx: torch.Size([32, 12])\n",
      "  total_nbr_fea shape: torch.Size([32, 12, 169])\n",
      "  fc_full input shape: torch.Size([384, 169])\n",
      "  fc_full weight shape: torch.Size([128, 169])\n",
      "  After conv 3, atom_fea shape: torch.Size([32, 64])\n",
      "Warning: Unexpected type for crystal_atom_idx: <class 'torch.Tensor'>. Converting to a list.\n",
      "  Processed crystal_atom_idx: [torch.Size([32])]\n",
      "  After pooling, crys_fea shape: torch.Size([1, 64])\n",
      "  After conv_to_fc, crys_fea shape: torch.Size([1, 128])\n",
      "  After conv_to_fc_softplus, crys_fea shape: torch.Size([1, 128])\n",
      "  Final output shape: torch.Size([1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_50800\\697418842.py:29: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "#CGCNN的卷积层输出特征图\n",
    "def plot_conv_outputs(conv_outputs, layer_name):\n",
    "    # 获取输出的形状\n",
    "    if len(conv_outputs.shape) == 2:\n",
    "        num_atoms, num_features = conv_outputs.shape\n",
    "    elif len(conv_outputs.shape) == 3:\n",
    "        batch_size, num_atoms, num_features = conv_outputs.shape\n",
    "        conv_outputs = conv_outputs[0]  # 只取第一个batch\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected shape: {conv_outputs.shape}\")\n",
    "    \n",
    "    # 创建一个网格来显示所有原子的特征\n",
    "    num_cols = min(8, num_atoms)\n",
    "    num_rows = (num_atoms - 1) // num_cols + 1\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 20))\n",
    "    fig.suptitle(f'Feature maps of {layer_name}')\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_atoms:\n",
    "            # 为每个原子创建一个热力图\n",
    "            im = ax.imshow(conv_outputs[i].detach().cpu().numpy().reshape(1, -1), \n",
    "                           aspect='auto', cmap='viridis')\n",
    "            ax.set_title(f'Atom {i}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # 添加颜色条\n",
    "    fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'conv_outputs_{layer_name}.png')\n",
    "    plt.close()\n",
    "\n",
    "# 在forward方法中收集卷积层输出\n",
    "conv_outputs = []\n",
    "def conv_hook(module, input, output):\n",
    "    conv_outputs.append(output)\n",
    "\n",
    "for conv in model.convs:\n",
    "    conv.register_forward_hook(conv_hook)\n",
    "\n",
    "# 运行模型\n",
    "with torch.no_grad():\n",
    "    model(atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx)\n",
    "\n",
    "# 绘制每个卷积层的输出\n",
    "for i, output in enumerate(conv_outputs):\n",
    "    plot_conv_outputs(output, f'conv_layer_{i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
